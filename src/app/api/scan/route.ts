/* eslint-disable @typescript-eslint/no-explicit-any */
// src/app/api/scan/route.ts
export const runtime = 'nodejs'
export const dynamic = 'force-dynamic'

import { NextRequest, NextResponse } from 'next/server'
import { createClient } from '@supabase/supabase-js'

interface PSIResult {
  categories: {
    performance: { score: number | null }
    accessibility: { score: number | null }
    seo: { score: number | null }
  }
  audits?: Record<string, unknown>
}

interface ScanRequest {
  site: string
  email: string
}

if (!process.env.SUPABASE_URL || !process.env.SUPABASE_SERVICE_ROLE_KEY) {
  throw new Error('Missing SUPABASE_URL or SUPABASE_SERVICE_ROLE_KEY')
}
const supabase = createClient<any, any>(
  process.env.SUPABASE_URL,
  process.env.SUPABASE_SERVICE_ROLE_KEY
)

function normalizeSite(raw: string): string {
  try {
    const u = new URL(raw.trim())
    u.hash = ''
    u.search = ''
    const cleanPath = u.pathname.replace(/\/+$/, '')
    return cleanPath ? `${u.origin}${cleanPath}` : u.origin
  } catch {
    let s = raw.trim().toLowerCase()
    if (s.endsWith('/')) s = s.slice(0, -1)
    return s
  }
}

export async function POST(req: NextRequest) {
  const logs: string[] = []
  try {
    logs.push('üè• [scan] start')
    console.log('‚Üí [scan] handler invoked')

    // Parse + validate
    logs.push('‚Ä¶ parsing body')
    console.log('‚Üí [scan] before JSON.parse')
    let body: unknown
    try {
      body = await req.json()
      console.log('‚Üí [scan] body parsed:', body)
    } catch (e: any) {
      logs.push(`‚ùå JSON parse error: ${e.message}`)
      console.log('‚Üí [scan] JSON parse failed:', e)
      return NextResponse.json({ logs, error: 'Invalid JSON payload' }, { status: 400 })
    }

    if (
      typeof body !== 'object' ||
      body === null ||
      typeof (body as any).site !== 'string' ||
      typeof (body as any).email !== 'string'
    ) {
      logs.push('‚ùå missing or invalid site/email')
      console.log('‚Üí [scan] validation failed on body:', body)
      return NextResponse.json({ logs, error: '`site` and `email` are required' }, { status: 400 })
    }
    const { site: rawSite, email } = body as ScanRequest
    logs.push(`üîç payload site=${rawSite}, email=${email}`)
    console.log('‚Üí [scan] validated payload')

    // Normalize
    logs.push('‚Ä¶ normalizing URL')
    const site = normalizeSite(rawSite)
    logs.push(`üåê normalized to ${site}`)
    console.log('‚Üí [scan] normalized URL:', site)

    // Cache check
    logs.push('‚Ä¶ checking cache/rate-limit')
    console.log('‚Üí [scan] before cache lookup')
    const todayKey = new Date().toISOString().slice(0, 10)
    let existing: { id: number } | null = null
    if (!(new URL(req.url).searchParams.get('force') === '1')) {
      const { data } = await supabase
        .from('scans')
        .select('id')
        .eq('site', site)
        .eq('created_day', todayKey)
        .single()
      existing = data
      console.log('‚Üí [scan] cache lookup result:', data)
    }
    if (existing) {
      logs.push('‚ÑπÔ∏è already scanned today ‚Üí checking cache validity')
      console.log('‚Üí [scan] fetching cached results for id', existing.id)
      const { data: prev } = await supabase
        .from('scans')
        .select('results')
        .eq('site', site)
        .order('created_at', { ascending: false })
        .limit(1)
        .single()
      console.log('‚Üí [scan] prev.results:', prev?.results)
      if (
        prev &&
        prev.results &&
        typeof (prev.results as any).categories === 'object' &&
        (prev.results as any).audits
      ) {
        logs.push('‚ÑπÔ∏è returning valid cached scan')
        console.log('‚Üí [scan] returning early with cache')
        return NextResponse.json({ logs, result: prev.results as PSIResult }, { status: 200 })
      }
      logs.push('‚ö†Ô∏è cached results invalid or missing ‚Üí running fresh scan')
      console.log('‚Üí [scan] cache invalid; continuing')
    } else {
      console.log('‚Üí [scan] no existing cache; proceeding')
    }

    // Reserve DB row
    logs.push('‚Ä¶ reserving DB row')
    console.log('‚Üí [scan] before DB insert')
    let scanId: number
    try {
      const { data, error } = await supabase
        .from('scans')
        .insert([{ site, email, results: {} }])
        .select('id')
        .single()
      if (error) throw error
      scanId = data.id
      logs.push(`‚úÖ reserved scan id=${scanId}`)
      console.log('‚Üí [scan] reserved id:', scanId)
    } catch (e: any) {
      console.log('‚Üí [scan] DB insert error:', e.message)
      if (e.message.includes('duplicate key value')) {
        logs.push('‚ö†Ô∏è placeholder insert conflict ‚Üí reusing existing row')
        const { data: existingRow } = await supabase
          .from('scans')
          .select('id')
          .eq('site', site)
          .eq('created_day', todayKey)
          .single()
        scanId = existingRow!.id
        console.log('‚Üí [scan] reused id:', scanId)
      } else {
        logs.push(`‚ùå DB insert failed: ${e.message}`)
        return NextResponse.json({ logs, error: 'Database error' }, { status: 500 })
      }
    }

    // Launch Chrome
    logs.push('‚Ä¶ launching Chrome')
    console.log('‚Üí [scan] before chrome-aws-lambda import')
    const chromeAws = (await import('chrome-aws-lambda')).default as any
    console.log('‚Üí [scan] imported chrome-aws-lambda, executablePath=', chromeAws.executablePath)
    const launcherMod = await import('chrome-launcher')
    console.log('‚Üí [scan] imported chrome-launcher')
    const chrome = await launcherMod.launch({
      chromePath: await chromeAws.executablePath,
      chromeFlags: chromeAws.args,
    })
    logs.push(`üöÄ AWS Chrome launched on port ${chrome.port}`)
    console.log('‚Üí [scan] chrome launched, port=', chrome.port)

    // Run Lighthouse
    logs.push('‚Ä¶ running Lighthouse')
    console.log('‚Üí [scan] before lighthouse import')
    const lhMod = await import('lighthouse')
    console.log('‚Üí [scan] imported lighthouse')
    const lighthouse = (lhMod as any).default || lhMod
    console.log('‚Üí [scan] invoking lighthouse')
    const runner = (await lighthouse(site, {
      port: chrome.port,
      output: 'json',
      logLevel: 'info',
      onlyCategories: ['performance', 'accessibility', 'seo'],
      throttlingMethod: 'provided',
    })) as { lhr: PSIResult }
    console.log('‚Üí [scan] lighthouse returned')
    const lhr = runner.lhr
    logs.push(`üìä scores: perf=${Math.round((lhr.categories.performance.score || 0) * 100)}%`)

    // Shutdown Chrome
    logs.push('‚Ä¶ shutting down Chrome')
    console.log('‚Üí [scan] before chrome.kill')
    await chrome.kill()
    logs.push('üîí Chrome killed')
    console.log('‚Üí [scan] chrome killed')

    // Save results
    logs.push('‚Ä¶ saving results')
    console.log('‚Üí [scan] before DB update')
    {
      const { error } = await supabase
        .from('scans')
        .update({ results: lhr })
        .eq('id', scanId)
      if (error) {
        logs.push(`‚ùå save failed: ${error.message}`)
        console.log('‚Üí [scan] DB update error:', error)
      } else {
        logs.push('üíæ results saved')
        console.log('‚Üí [scan] results saved')
      }
    }

    logs.push('üéâ done')
    console.log('‚Üí [scan] completed successfully, returning')
    return NextResponse.json({ logs, result: lhr }, { status: 200 })
  } catch (err: any) {
    console.error('üî• uncaught:', err)
    logs.push(`‚ùå uncaught: ${err.message}`)
    return NextResponse.json({ logs, error: 'Internal error' }, { status: 500 })
  }
}
